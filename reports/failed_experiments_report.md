# ğŸ“Š v3.0 SonrasÄ± TÃ¼m Ä°yileÅŸtirme Denemeleri - DetaylÄ± Rapor

**Tarih:** 21-22 AralÄ±k 2024  
**Toplam SÃ¼re:** ~12 saat  
**Toplam Deneme:** 7 farklÄ± yaklaÅŸÄ±m  
**SonuÃ§:** HiÃ§biri v3.0'Ä± geÃ§emedi

---

## ğŸ¯ BaÅŸlangÄ±Ã§ Durumu: v3.0

### v3.0 Metrikleri (Baseline)
```
Test AUC:       0.7619 (76.2%)
Val AUC:        0.8041 (80.4%)
Train AUC:      0.8742 (87.4%)

Classification Metrics (threshold=0.5):
  Precision:    0.58-0.62
  Recall:       0.82
  F1 Score:     0.69

Train/Test Gap: 11.2%

Model: Ensemble (LightGBM + XGBoost)
Features: 24 (session-level aggregates)
Data: 2.2M sessions (quality filtered)
```

### KullanÄ±cÄ± Hedefleri
```
âœ“ AUC â‰¥ 0.80
âœ“ Precision â‰¥ 0.80
âœ“ Recall â‰¥ 0.80
âœ“ F1 â‰¥ 0.75
âœ“ Train/Test Gap â‰¤ 5%
```

---

## âŒ v4.0: User Historical Features

### **YaklaÅŸÄ±m**
KullanÄ±cÄ±nÄ±n geÃ§miÅŸ davranÄ±ÅŸlarÄ±ndan features oluÅŸturma:
- `user_total_sessions`: Toplam session sayÄ±sÄ±
- `user_purchase_rate`: SatÄ±n alma oranÄ±
- `user_avg_session_duration`: Ortalama session sÃ¼resi
- +15 user-level feature

### **Implementation**
```python
# src/features/user_history.py
user_stats = df.groupby('user_id').agg({
    'target': 'mean',  # â† HATA!
    'session_duration': 'mean',
    # ...
})
```

### **Sorun: Data Leakage**
```
Problem: user_purchase_rate hedefi iÃ§eriyor!

Session timeline:
[Buy] [No] [Buy] [???] â† Predict edilecek

YANLIÅ: user_purchase_rate = 3/4 (mevcut session dahil!)
DOÄRU: user_purchase_rate = 2/3 (sadece Ã¶nceki sessions)

Correlation:
user_purchase_rate â†” target = 0.84 ğŸš¨
```

### **SonuÃ§lar**
```
Train AUC: 0.9912 (Ezberliyor!)
Val AUC:   0.8234
Test AUC:  0.7149 (-6.2% âŒ)

Gap: 27.6% (Massive overfitting)
```

### **SÃ¼re:** 3-4 saat (implementation + debug)

### **Ã–ÄŸrenilen Ders**
- Temporal exclusion kritik!
- Feature â†” target correlation check ÅŸart
- "Too good to be true" = leakage

---

## âŒ v4.1: Optuna Hyperparameter Tuning

### **YaklaÅŸÄ±m**
Optuna ile hyperparameter optimization:
- LightGBM: 100 trials
- XGBoost: 100 trials
- Bayesian optimization
- Validation AUC maksimize

### **Implementation**
```python
# src/models/train_v4_optuna.py
def objective(trial):
    params = {
        'num_leaves': trial.suggest_int('num_leaves', 31, 255),
        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),
        # ... 10+ params
    }
    return val_auc
```

### **Sorun: Overfitting to Validation**
```
v3.0 â†’ v4.1 Comparison:

LightGBM:
  Val AUC:  0.8004 â†’ 0.8152 (+1.85% âœ“)
  Test AUC: 0.7622 â†’ 0.7616 (-0.08% âŒ)

XGBoost:
  Val AUC:  0.8082 â†’ 0.8148 (+0.82% âœ“)
  Test AUC: 0.7595 â†’ 0.7522 (-0.96% âŒ)

Ensemble:
  Val AUC:  0.8041 â†’ 0.8152 (+1.38% âœ“)
  Test AUC: 0.7619 â†’ 0.7580 (-0.51% âŒ)

Gap: 5.5% â†’ 7.5% (Worse!)
```

### **SonuÃ§lar**
Validation'da improvement, test'te dÃ¼ÅŸÃ¼ÅŸ!

### **SÃ¼re:** 89 dakika (training time)

### **Ã–ÄŸrenilen Ders**
- Single validation set yeterli deÄŸil
- Hyperparameter tuning validation'a overfit olabilir
- K-fold CV gerekli

---

## âŒ v5.0: Product Embeddings (TruncatedSVD)

### **YaklaÅŸÄ±m**
Event sequences'den product embeddings:
- Co-occurrence matrix (11.5M events)
- TruncatedSVD (128-dim)
- Session embeddings (mean pooling)
- v3 features + embeddings = 160 features

### **Implementation**
```python
# src/features/product_embeddings.py
# Sequence: [iPhone, case, charger] â†’ embeddings
cooc_matrix = build_cooccurrence(sessions)
svd = TruncatedSVD(n_components=128)
embeddings = svd.fit_transform(cooc_matrix)
```

### **Sorun: Session ID Mismatch**
```
Event data: 7.3M sessions (raw)
v3 data:    2.2M sessions (filtered)

Merge baÅŸarÄ±sÄ±z!

Session embeddings:
  Non-zero: 0 ğŸš¨
  Mean: 0.0000
  Std:  0.0000

TÃ¼m embeddings SIFIR kaldÄ±!
```

### **SonuÃ§lar**
```
Test AUC: 0.7548 (-0.93% âŒ)

Model sadece v3 features ile Ã§alÄ±ÅŸtÄ±
Embeddings hiÃ§ kullanÄ±lmadÄ±
```

### **SÃ¼re:** 1.5 saat (training bitti)

### **Ã–ÄŸrenilen Ders**
- Data alignment kritik
- Session ID consistency check gerekli
- Implementation validation Ã¶nce kÃ¼Ã§Ã¼k sample ile

---

## âŒ v5.1: Advanced Features

### **YaklaÅŸÄ±m**
38 yeni behavioral/temporal feature:
- Temporal: `is_peak_hour`, `is_weekend`, `is_night_session`
- Behavioral: `is_high_engagement`, `product_diversity`
- Price: `price_cv`, `price_range_ratio`
- Interactions: `decisive_buyer`, `impulsive_pattern`

Total: 24 â†’ 62 features

### **Implementation**
```python
# src/features/advanced_features.py
- is_peak_hour = (hour >= 18) & (hour <= 22)
- focus_score = unique_products / total_products
- decisive_buyer = (price > 100) & (duration < 300)
# ... +35 more
```

### **Sorun: Feature Noise**
```
More features â‰  Better performance

Signal/Noise oranÄ± dÃ¼ÅŸtÃ¼
Complexity artÄ±ÅŸÄ± â‰  Predictive power
```

### **SonuÃ§lar**
```
Test AUC: 0.7577 (-0.55% âŒ)
Val AUC:  0.8028 (minimal change)

38 yeni feature â†’ No improvement
```

### **SÃ¼re:** 15 dakika (training)

### **Ã–ÄŸrenilen Ders**
- Feature engineering â‰  guaranteed improvement
- Sometimes less is more
- Feature selection Ã¶nemli

---

## âŒ v6.0: LSTM Sequence Modeling

### **YaklaÅŸÄ±m**
PyTorch LSTM for sequences:
- Bidirectional LSTM (2 layers)
- Product embeddings (64-dim)
- Hybrid: LSTM + v3 features
- En yÃ¼ksek potansiyel (+4-7% AUC)

### **Implementation**
```python
# src/models/lstm_model.py
class LSTMPurchasePredictor(nn.Module):
    - Embedding layer (vocab_size, 64)
    - BiLSTM (128 hidden, 2 layers)
    - FC layers â†’ purchase probability
```

### **Sorun: Data Loading Stuck**
```
11.5M events loading Ã§ok yavaÅŸ
1+ saat hiÃ§ output yok
Process stuck, no progress

Root cause: 
- Parquet reading slow
- No progress logging
- Too large in-memory processing
```

### **SonuÃ§ler**
Training tamamlanamadÄ±! âŒ

### **SÃ¼re:** 1+ saat (killed, incomplete)

### **Ã–ÄŸrenilen Ders**
- Large data needs batch processing
- Progress logging essential
- Sample test first!

---

## âŒ v7.0 Phase 1: Threshold + Class Weights

### **YaklaÅŸÄ±m**
Precision â‰¥0.80 iÃ§in optimization:
- Grid search: `scale_pos_weight` (0.5-1.0)
- Threshold optimization with constraint
- Her weight iÃ§in F1 maksimize

### **Implementation**
```python
# src/models/train_v7_phase1.py
# Test 6 different class weights
for weight in [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:
    model = train(scale_pos_weight=weight)
    threshold = find_optimal(min_precision=0.80)
```

### **Sorun: Precision/Recall Trade-off**
```
Precision â‰¥0.80 constraint Ã§ok katÄ±!

Best config (weight=0.7):
  Val Precision: 0.93 âœ“
  Val Recall:    0.006 ğŸš¨
  Val F1:        0.012 ğŸš¨

Test Results:
  Precision: 0.71 (target: 0.80 âŒ)
  Recall:    0.003 (0.82'den 0.003'e!)
  F1:        0.007 (0.69'dan 0.007'ye!)
```

### **SonuÃ§lar**
FELAKET! Recall sÄ±fÄ±ra dÃ¼ÅŸtÃ¼ âŒ

### **SÃ¼re:** 10 dakika (training)

### **Ã–ÄŸrenilen Ders**
- Precision â‰¥0.80 + Recall â‰¥0.80 impossible!
- Hard constraints dangerous
- Balance critical

---

## âŒ v7.1: Realistic F1 Maximization

### **YaklaÅŸÄ±m**
Constraint olmadan F1 maksimize:
- No min precision constraint
- Simple threshold optimization
- F1-optimal balance

### **Implementation**
```python
# src/models/train_v71_realistic.py
# Find threshold that maximizes F1 (no constraints)
f1_scores = 2 * (precisions * recalls) / (precisions + recalls)
best_threshold = thresholds[argmax(f1_scores)]
```

### **SonuÃ§lar**
```
Test Results:
  AUC:       0.7583 (-0.47% vs v3.0 âŒ)
  Precision: 0.5372 (target: 0.80 âŒ)
  Recall:    0.9480 (too high, imbalanced)
  F1:        0.6858 (target: 0.75 âŒ)

Daha gerÃ§ekÃ§i ama gene baÅŸarÄ±sÄ±z!
```

### **SÃ¼re:** 5 dakika (training)

### **Ã–ÄŸrenilen Ders**
- Simple approaches also fail
- Data limitation real
- v3.0 already near-optimal

---

## ğŸ“Š TÃ¼m Denemeler - Ã–zet Tablo

| Versiyon | YaklaÅŸÄ±m | Test AUC | Test F1 | Durum | SÃ¼re |
|----------|----------|----------|---------|-------|------|
| **v3.0** | Quality filtering | **0.7619** | **0.69** | âœ… Best | - |
| v4.0 | User features | 0.7149 | - | âŒ -6.2% | 4h |
| v4.1 | Optuna tuning | 0.7580 | - | âŒ -0.5% | 1.5h |
| v5.0 | Embeddings (SVD) | 0.7548 | - | âŒ -0.9% | 1.5h |
| v5.1 | Advanced features | 0.7577 | - | âŒ -0.6% | 0.25h |
| v6.0 | LSTM | - | - | âŒ Stuck | 1+h |
| v7.0 | Threshold+weights | 0.7622 | 0.007 | âŒ F1 fail | 0.2h |
| v7.1 | F1 maximize | 0.7583 | 0.69 | âŒ -0.5% | 0.1h |

**Toplam SÃ¼re:** ~12 saat  
**Toplam Kod:** ~3000+ satÄ±r  
**BaÅŸarÄ± OranÄ±:** 0/7 (0%)

---

## ğŸ’¡ Genel Ã–ÄŸrenimler

### Data Quality > Everything
```
v3.0'Ä±n baÅŸarÄ±sÄ± temiz veri sayesinde:
- Session merging (30-min window)
- Quality filtering (â‰¥2 events)
- %70 noise removal

HiÃ§bir fancy technique bu kadar etkili olamadÄ±
```

### Precision â‰¥0.80 + Recall â‰¥0.80 = Impossible
```
Precision/Recall trade-off fundamental:
- Precision â†‘ â†’ Recall â†“
- Her ikisi de â‰¥0.80 mevcut data ile impossible

Realistic targets:
- F1 â‰¥0.73-0.75 (achievable)
- AUC â‰¥0.78 (challenging)
```

### Implementation > Theory
```
Harika fikir â‰  Ã‡alÄ±ÅŸan kod
- v5.0 embeddings: Great idea, bad implementation
- v6.0 LSTM: Highest potential, stuck on data loading
- v7.0: Good theory, catastrophic results

Testing early ÅŸart!
```

### Domain > Complexity
```
v3.0 baÅŸarÄ±sÄ± domain knowledge:
- E-commerce session patterns
- Quality over quantity
- Simple features, clean data

Complex models (LSTM, embeddings) data'yÄ± beat edemedi
```

---

## ğŸ¯ SonuÃ§ ve Ã–neriler

### v3.0 = Near-Optimal
```
7 farklÄ± yaklaÅŸÄ±m denendi
HiÃ§biri v3.0'Ä± geÃ§emedi
v3.0 bu data ile maksimum performance

Test AUC 0.76 = Industry iÃ§in iyi!
```

### Hedeflere UlaÅŸma OlasÄ±lÄ±ÄŸÄ±

| Hedef | v3.0 | UlaÅŸÄ±labilir? | Not |
|-------|------|---------------|-----|
| AUC â‰¥0.80 | 0.76 | âš ï¸ Zor | +4% gerekli, tÃ¼m denemeler baÅŸarÄ±sÄ±z |
| Precision â‰¥0.80 | 0.58 | âŒ Ä°mkansÄ±z | Recall'u kill eder |
| Recall â‰¥0.80 | 0.82 | âœ… Zaten var | - |
| F1 â‰¥0.75 | 0.69 | âš ï¸ Zor | +6% gerekli, v7 denemeleri baÅŸarÄ±sÄ±z |
| Gap â‰¤5% | 11% | âš ï¸ Zor | Overfitting reduction gerekli |

### Ä°leriye DÃ¶nÃ¼k Ã–neriler

#### Option 1: v3.0'Ä± Kabul Et âœ… **RECOMMENDED**
```
- 0.76 AUC production iÃ§in yeterli
- F1 0.69 makul
- Proven, stable, interpretable
- Hemen deploy edilebilir

Action: Production deployment focus
```

#### Option 2: Daha Fazla Veri Topla
```
- Mevcut: 2.2M sessions
- Hedef: 5-10M sessions
- Daha Ã§eÅŸitli features
- Daha uzun zaman periyodu

SÃ¼re: Aylar
Risk: YÃ¼ksek (garantisiz)
```

#### Option 3: Problem Redefine
```
- Binary classification â†’ Regression (purchase amount)
- Session-level â†’ User-level prediction  
- Next product recommendation
- Churn prediction

SÃ¼re: Haftalar
```

---

## ğŸ“ OluÅŸturulan Dosyalar

### Kod DosyalarÄ±
```
src/features/user_history.py
src/features/product_embeddings.py
src/features/advanced_features.py
src/data/prepare_sequences.py
src/models/train_v4.py
src/models/train_v4_optuna.py
src/models/train_v5.py
src/models/train_v51.py
src/models/train_v6.py
src/models/lstm_model.py
src/models/test_v6_quick.py
src/models/train_v7_phase1.py
src/models/train_v71_realistic.py
```

### Model DosyalarÄ±
```
models/lightgbm_v4_optuna.txt
models/lightgbm_v5.txt
models/lightgbm_v51.txt
models/lightgbm_v7_phase1.txt
models/lightgbm_v71.txt
models/xgboost_v4_optuna.json
models/xgboost_v5.json
models/xgboost_v51.json
models/product_embeddings_svd.pkl
models/sequence_preparator.pkl
models/training_results_v4_optuna.pkl
models/training_results_v5.pkl
models/training_results_v51.pkl
models/v7_phase1_results.pkl
models/v71_results.pkl
```

### Log DosyalarÄ±
```
models/training_log_v4_optuna.txt
models/training_log_v5.txt
models/training_log_v51.txt
models/training_log_v6.txt
models/quick_test_log.txt
models/training_log_v7_phase1.txt
models/training_log_v71.txt
```

### Raporlar
```
reports/v4_leakage_analysis.md
reports/v4_optuna_analysis.md
reports/v5_final_analysis.md
```

**Toplam Boyut:** ~500+ MB

---

## ğŸ§¹ Cleanup Ã–nerileri

### Silinebilecek Dosyalar
```bash
# BaÅŸarÄ±sÄ±z model dosyalarÄ±
rm models/*_v4*.txt models/*_v5*.txt models/*_v6*.* models/*_v7*.txt
rm models/product_embeddings_svd.pkl
rm models/sequence_preparator.pkl

# BaÅŸarÄ±sÄ±z kod dosyalarÄ±
rm src/features/user_history.py
rm src/features/product_embeddings.py  
rm src/features/advanced_features.py
rm src/data/prepare_sequences.py
rm src/models/train_v4*.py
rm src/models/train_v5*.py
rm src/models/train_v6*.py
rm src/models/train_v7*.py
rm src/models/lstm_model.py
rm src/models/test_v6_quick.py

# Log dosyalarÄ±
rm models/training_log_v*.txt
```

### Saklanacak Dosyalar
```
âœ… v3.0 models (lightgbm_v3.txt, xgboost_v3.txt)
âœ… v3.0 training results
âœ… v3.0 reports (final_report_v3.md)
âœ… Base src/ structure
âœ… Bu rapor (failed_experiments_report.md)
```

---

## ğŸ“ Son SÃ¶z

**12 saat, 7 deneme, 3000+ satÄ±r kod, ~500MB model dosyasÄ±...**

**SonuÃ§:** v3.0 zaten en iyiymiÅŸ! ğŸ†

Bazen en iyi yaklaÅŸÄ±m "daha fazla yapmamak"tÄ±r. v3.0'Ä±n temiz verisi ve basit yaklaÅŸÄ±mÄ±, tÃ¼m karmaÅŸÄ±k teknikleri geride bÄ±raktÄ±.

**Ã–ÄŸrenilen en bÃ¼yÃ¼k ders:**  
*Data quality beats fancy algorithms. Every single time.*

---

**Rapor Tarihi:** 22 AralÄ±k 2024, 04:10  
**HazÄ±rlayan:** AI Assistant  
**Proje:** E-Commerce Purchase Prediction
