# ğŸ›’ E-Commerce SatÄ±n Alma Tahmini

[![Python](https://img.shields.io/badge/Python-3.14-blue.svg)](https://www.python.org/)
[![Lisans](https://img.shields.io/badge/Lisans-MIT-green.svg)]()
[![Durum](https://img.shields.io/badge/Durum-TamamlandÄ±-success.svg)]()
[![DokÃ¼mantasyon](https://img.shields.io/badge/DÃ¶kÃ¼manlar-KapsamlÄ±-brightgreen.svg)]()

> E-ticaret kullanÄ±cÄ±larÄ±nÄ±n tarama davranÄ±ÅŸlarÄ±ndan satÄ±n alma niyetini tahmin eden makine Ã¶ÄŸrenmesi projesi. 10 farklÄ± optimizasyon yaklaÅŸÄ±mÄ±nÄ±n sistematik incelemesi ile **veri kalitesinin model karmaÅŸÄ±klÄ±ÄŸÄ±ndan daha Ã¶nemli** olduÄŸunu gÃ¶steriyor.

**SonuÃ§:** KapsamlÄ± optimizasyon denemelerinden sonra v3.0 LightGBM Baseline en dengeli model olarak kaldÄ±.

---

## ğŸ“‹ Ä°Ã§indekiler

- [HÄ±zlÄ± BakÄ±ÅŸ](#-hÄ±zlÄ±-bakÄ±ÅŸ)
- [Temel SonuÃ§lar](#-temel-sonuÃ§lar)
- [Proje YolculuÄŸu](#-proje-yolculuÄŸu)
- [Ã–nemli Ã‡Ä±karÄ±mlar](#-Ã¶nemli-Ã§Ä±karÄ±mlar)
- [DokÃ¼mantasyon](#-dokÃ¼mantasyon)
- [Kurulum](#-kurulum)
- [KullanÄ±m](#-kullanÄ±m)
- [Proje YapÄ±sÄ±](#-proje-yapÄ±sÄ±)
- [GÃ¶rseller](#-gÃ¶rseller)
- [Metodoloji](#-metodoloji)

---

## ğŸ¯ HÄ±zlÄ± BakÄ±ÅŸ

### Problem TanÄ±mÄ±
E-ticaret kullanÄ±cÄ±sÄ±nÄ±n tarama oturumu sÄ±rasÄ±nda satÄ±n alma yapÄ±p yapmayacaÄŸÄ±nÄ± davranÄ±ÅŸ desenlerine gÃ¶re tahmin etmek.

### Dataset
- **Source:** E-commerce platform event logs (2020)
- **Kaggle:** [RecSys 2020 E-Commerce Dataset](https://www.kaggle.com/datasets/dschettler8845/recsys-2020-ecommerce-dataset)
- **Size:** 11.5M events â†’ 2.2M quality sessions
- **Features:** 24 engineered session-level features
- **Target:** Binary (Purchase vs. No Purchase)
- **Class Distribution:** %15 positive (imbalanced)

> **Not:** Veri dosyalarÄ± (~600MB) GitHub'da bulunmamaktadÄ±r. YukarÄ±daki Kaggle linkinden indirebilirsiniz.

### YaklaÅŸÄ±m
**Veri Kalitesi Ã–ncelikli:** Temiz veri ile basit modeller, karmaÅŸÄ±k Ã¶zelliklerle gÃ¼rÃ¼ltÃ¼lÃ¼ veriden daha iyi performans gÃ¶sterir.

```
Ham Veri (11.5M event)
    â†“ Session BirleÅŸtirme
  Kalite Filtreleme
    â†“ Ã–zellik MÃ¼hendisliÄŸi  
Final Veri (2.2M session, 24 Ã¶zellik)
    â†“ v3.0 LightGBM (varsayÄ±lan parametreler)
Final Model (Test AUC: 0.7619, Recall: 0.98)
```

---

## ğŸ† Temel SonuÃ§lar

### Final Model: v3.0 LightGBM Baseline

| Metrik | DeÄŸer | AÃ§Ä±klama |
|--------|-------|----------|
| **Test AUC** | 0.7619 | GÃ¼Ã§lÃ¼ sÄ±ralama yeteneÄŸi |
| **Test F1** | 0.69 | Dengeli precision-recall |
| **Test Precision** | 0.65 | Pozitif tahminlerin %65'i doÄŸru |
| **Test Recall** | **0.98** â­ | **100 mÃ¼ÅŸteriden 98'ini yakalÄ±yor!** |
| **Train-Test Gap** | %11 | DÃ¼ÅŸÃ¼k overfitting |

### Bu SonuÃ§lar Neden Ã–nemli?

**Ä°ÅŸ Etkisi:** 100 potansiyel mÃ¼ÅŸteriden 98'ini yakalÄ±yor, sadece 2'sini kaÃ§Ä±rÄ±yor.

Bu olaÄŸanÃ¼stÃ¼ recall oranÄ± ÅŸunlarÄ± saÄŸlÄ±yor:
- False negative'lerden minimal gelir kaybÄ±
- Verimli pazarlama kampanyasÄ± hedefleme
- Maksimum mÃ¼ÅŸteri dÃ¶nÃ¼ÅŸÃ¼mÃ¼ yakalama

---

## ğŸ”¬ Proje YolculuÄŸu

Bu proje, saÄŸlam v3.0 baseline sonuÃ§larÄ± elde ettikten sonra **10 farklÄ± optimizasyon yaklaÅŸÄ±mÄ±nÄ±** sistematik olarak test etti.

### Versiyon Evrimi

| Versiyon | YaklaÅŸÄ±m | Test AUC | Temel Ä°yileÅŸtirme |
|----------|----------|----------|-------------------|
| v1.0 | Ä°lk Baseline | 0.5936 | Ä°lk implementasyon |
| v2.0 | GeliÅŸmiÅŸ Ã–zellikler + Tuning | 0.6107 | +17 Ã¶zellik, hiperparametre optimizasyonu |
| **v3.0** | **Veri Kalitesi OdaklÄ±** | **0.7619** | **Session birleÅŸtirme, kalite filtreleme (+%28.4)** |

**Temel Ã‡Ä±karÄ±m:** v1.0 â†’ v3.0 arasÄ±nda +%28.4 AUC iyileÅŸtirmesi **veri kalitesi** ile saÄŸlandÄ±, model karmaÅŸÄ±klÄ±ÄŸÄ± ile deÄŸil.

### Optimizasyon Denemeleri (Hepsi v3.0'Ä± GeÃ§emedi)

v3.0'dan sonra, performansÄ± daha da artÄ±rmak iÃ§in **10 sofistike yaklaÅŸÄ±m** test edildi:

#### Kategori 1: Ã–zellik MÃ¼hendisliÄŸi
1. **v4.0 - Agresif Ã–zellik Ã‡Ä±karma** (16 Ã¶zellik)
   - SonuÃ§: AUC 0.7398 (-%2.9) âŒ
   - Ã–ÄŸrenilen: Ã‡Ä±karÄ±lan Ã¶zellikler kombinasyon halinde deÄŸerliymiÅŸ

2. **v5.0 - Eklemeli MÃ¼hendislik** (68 Ã¶zellik)
   - SonuÃ§: AUC 0.7588 (-%0.4), Gap +%3 âŒ
   - Ã–ÄŸrenilen: Daha fazla Ã¶zellik â‰  daha iyi performans

#### Kategori 2: GeliÅŸmiÅŸ Modelleme
3. **v6.0 - Stacking Ensemble**
   - SonuÃ§: AUC 0.7678 (+%0.8), ama Recall 0.77'ye dÃ¼ÅŸtÃ¼ âŒ
   - Ã–ÄŸrenilen: YÃ¼ksek AUC daha iyi model anlamÄ±na gelmez

#### Kategori 3: Sistematik Optimizasyon

**Phase 1: AkÄ±llÄ± Ã–zellik SeÃ§imi**
- SonuÃ§: Minimal iyileÅŸtirme (+%0.13)

**Phase 2: Algoritma Testi**
- Test Edilenler: ExtraTrees, XGBoost, Random Forest, HistGradientBoosting
- SonuÃ§: HiÃ§biri v3.0'Ä±n recall'Ä±nÄ± yakalayamadÄ±

**Phase 3: Hiperparametre Optimizasyonu (Optuna)**
- Model baÅŸÄ±na 25 deneme, paralel Ã§alÄ±ÅŸtÄ±rma (Mac + Colab)
- En Ä°yi: ExtraTrees (AUC 0.7751)
- Problem: Recall 0.77'ye dÃ¼ÅŸtÃ¼ (**%21 mÃ¼ÅŸteri kaybÄ±!**)

#### Kategori 4: Ensemble YÃ¶ntemleri (6 varyasyon)
4-9. Ã‡eÅŸitli ensemble yaklaÅŸÄ±mlarÄ± test edildi:
   - Grid search aÄŸÄ±rlÄ±klÄ± oylama
   - EÅŸit aÄŸÄ±rlÄ±klar
   - Meta-learner ile stacking
   - Ã‡ok-amaÃ§lÄ± optimizasyon (6 varyant)
   - Hepsi v3.0'Ä±n recall'Ä±nÄ± koruyamadÄ±

10. **v3.0 Hiperparametre Tuning** (50 deneme)
    - Validation AUC: 0.8154 (mÃ¼kemmel!)
    - Test AUC: 0.7555 (-%0.84) âŒ
    - Ciddi overfitting!

### Final KarÅŸÄ±laÅŸtÄ±rma

| Model | Test AUC | F1 | Recall | Gap | Kazanan |
|-------|----------|-----|--------|-----|---------|
| **v3.0 Baseline** | **0.7619** | **0.69** â˜… | **0.98** â˜…â˜…â˜… | **%11** â˜… | âœ… En Ä°yi |
| ExtraTrees (Optimized) | **0.7751** â˜… | 0.67 | 0.77 | %13.6 | âŒ DÃ¼ÅŸÃ¼k Recall |
| XGBoost (Colab) | 0.7691 | 0.64 | 0.67 | %13.6 | âŒ DÃ¼ÅŸÃ¼k F1 |
| Equal Weights Ensemble | 0.7689 | 0.67 | 0.80 | %13.6 | âŒ SeyreltilmiÅŸ gÃ¼Ã§ |
| Stacking Ensemble | 0.7678 | 0.67 | 0.77 | %13.6 | âŒ KarmaÅŸÄ±k, dÃ¼ÅŸÃ¼k recall |

**v3.0, 5 metrikten 4'Ã¼nde kazanÄ±yor!** â­

---

## ğŸ’¡ Ã–nemli Ã‡Ä±karÄ±mlar

### 1. Veri Kalitesi > Model KarmaÅŸÄ±klÄ±ÄŸÄ±
- v3.0'Ä±n baÅŸarÄ±sÄ± temiz veriden geliyor (session birleÅŸtirme, kalite filtreleme)
- 68 Ã¶zellik + stacking < 24 Ã¶zellik + varsayÄ±lan LightGBM

### 2. Validation â‰  Test
- XGBoost ve tuned v3.0: MÃ¼kemmel validation, kÃ¶tÃ¼ test
- ExtraTrees: KÃ¶tÃ¼ validation, en iyi test AUC
- **Ã–ÄŸrenilen:** Grid search validation set'e overfit olabilir

### 3. Recall VazgeÃ§ilmezdir
- v3.0'Ä±n 0.98 recall'Ä± = **iÅŸ iÃ§in altÄ±n**
- 100 mÃ¼ÅŸteri â†’ model 98'ini yakalar, sadece 2'sini kaÃ§Ä±rÄ±r
- ExtraTrees 21 mÃ¼ÅŸteri kaÃ§Ä±rÄ±yor (10x daha kÃ¶tÃ¼!)
- Gelir etkisi Ã§ok bÃ¼yÃ¼k

### 4. Ensemble BÃ¼yÃ¼sÃ¼ Yoktur  
- 10 ensemble varyasyonu test edildi
- Modeller birbirini tamamlamadÄ± (benzer hata desenleri)
- Tek gÃ¼Ã§lÃ¼ model > zayÄ±f ensemble

### 5. Basit GÃ¼zeldir
- v3.0: 24 Ã¶zellik, varsayÄ±lan parametreler, 237KB dosya
- v6.0: 68 Ã¶zellik, stacking, meta-learner, karmaÅŸÄ±k
- **v3.0 kazandÄ±!**

### 6. VarsayÄ±lan Parametreler Optimal Olabilir
- Agresif Optuna tuning (50 deneme) v3.0'Ä± kÃ¶tÃ¼leÅŸtirdi
- VarsayÄ±lan LightGBM parametreleri iyi ayarlanmÄ±ÅŸ
- **Ã–ÄŸrenilen:** Domain bilgisi > kÃ¶r optimizasyon

---

## ğŸ“š DokÃ¼mantasyon

### Temel DokÃ¼manlar

#### Projeyi Anlamak Ä°Ã§in
- **[Bu README]** - Proje Ã¶zeti ve hÄ±zlÄ± baÅŸlangÄ±Ã§
- **[FINAL_PROJECT_REPORT.md](reports/FINAL_PROJECT_REPORT.md)** - TÃ¼m 10 deneyin kapsamlÄ± analizi (635 satÄ±r)
- **[PROJECT_PRESENTATION.md](reports/PROJECT_PRESENTATION.md)** - 10-15 dk sunum formatÄ±

#### Veriyi Anlamak Ä°Ã§in
- **[ORIGINAL_DATASET_REPORT.md](final_reports/ORIGINAL_DATASET_REPORT.md)** - Ham veri analizi (11.5M event)
- **[PROCESSED_DATASET_REPORT.md](final_reports/PROCESSED_DATASET_REPORT.md)** - Ä°ÅŸlenmiÅŸ veri (2.2M session, 24 Ã¶zellik)

#### Teknik Detaylar
- **[final_report_v3.md](reports/final_report_v3.md)** - v3.0 metodoloji detaylarÄ±
- **[final_report_v6.md](reports/final_report_v6.md)** - v6.0 stacking ensemble (neden baÅŸarÄ±sÄ±z oldu)

#### Kod DokÃ¼mantasyonu
- **[src/README.md](src/README.md)** - Kaynak kod yapÄ±sÄ± (~5,100 satÄ±r Python)
- **[data/README.md](data/README.md)** - Veri organizasyonu
- **[models/README.md](models/README.md)** - EÄŸitilmiÅŸ modeller
- **[reports/README.md](reports/README.md)** - Raporlar ve gÃ¶rseller

---

## ğŸ“Š GÃ¶rseller

### Profesyonel GÃ¶rseller

`reports/final_visuals/` klasÃ¶rÃ¼nde 10 profesyonel gÃ¶rsel:

**Temel Set (6 gÃ¶rsel):**
1. Model KarÅŸÄ±laÅŸtÄ±rma Tablosu - TÃ¼m modeller & metrikler
2. Confusion Matrix (v3.0) - TP/FP/TN/FN daÄŸÄ±lÄ±mÄ±
3. ROC EÄŸrisi - AUC gÃ¶rselleÅŸtirmesi
4. Ã–zellik Ã–nemi - En Ã¶nemli 15 Ã¶zellik
5. AUC KarÅŸÄ±laÅŸtÄ±rma Bar Chart - Model sÄ±ralamasÄ±
6. Ä°ÅŸ Etkisi - 98/100 mÃ¼ÅŸteri yakalama

**Ek Set (4 gÃ¶rsel):**
7. Veri DÃ¶nÃ¼ÅŸÃ¼m AkÄ±ÅŸÄ± - 11.5Mâ†’2.2M pipeline
8. BaÅŸarÄ±sÄ±z Denemeler Zaman Ã‡izelgesi - 10 deneme yolculuÄŸu
9. Precision-Recall EÄŸrisi - Dengesiz veri performansÄ±
10. SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± - %85 vs %15 dengesizlik

TÃ¼mÃ¼ Python (matplotlib/seaborn) ile oluÅŸturuldu. Detaylar iÃ§in [reports/final_visuals/README.md](reports/final_visuals/README.md).

---

## ğŸš€ Kurulum

### Gereksinimler
- Python 3.14+
- 2.2GB disk alanÄ± (veri iÃ§in)
- 23MB (modeller iÃ§in)

### HÄ±zlÄ± Kurulum

```bash
# Repository'yi klonla
git clone https://github.com/recepztrk/ecommerce-purchase-prediction.git
cd ecommerce-purchase-prediction

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt
```

#### BaÄŸÄ±mlÄ±lÄ±klar
```
pandas==2.1.4
numpy==1.26.2
scikit-learn==1.3.2
lightgbm==4.1.0
xgboost==2.0.3
pyarrow==14.0.1
matplotlib==3.8.2
seaborn==0.13.0
optuna==3.5.0
imbalanced-learn==0.11.0
```

---

## ğŸ’» KullanÄ±m

### Production Model'i YÃ¼kle (v3.0)

```python
import lightgbm as lgb
import pandas as pd

# v3.0 baseline model'i yÃ¼kle
model = lgb.Booster(model_file='models/lightgbm_v3.txt')

# Test verisini yÃ¼kle
X_test = pd.read_parquet('data/v3/test_sessions_v3.parquet')

# Tahmin al (0-1 arasÄ± olasÄ±lÄ±k skorlarÄ±)
predictions = model.predict(
    X_test.drop(['target', 'user_session', 'user_id'], axis=1)
)

# Ã–rnek Ã§Ä±ktÄ±
print(f"MÃ¼ÅŸteri 1: %{predictions[0]:.2%} satÄ±n alma olasÄ±lÄ±ÄŸÄ±")
# Ã‡Ä±ktÄ±: MÃ¼ÅŸteri 1: %92.5 satÄ±n alma olasÄ±lÄ±ÄŸÄ±
```

### Ä°ÅŸ UygulamalarÄ±

```python
# OlasÄ±lÄ±k skorlarÄ±na gÃ¶re kampanya hedefleme
campaigns = {
    'premium': predictions > 0.85,  # En Ã¼st %10 - Kesin gÃ¶nder
    'standard': (predictions > 0.60) & (predictions <= 0.85),  # Orta - Ä°ndirimle gÃ¶nder
    'low_priority': (predictions > 0.50) & (predictions <= 0.60)  # DÃ¼ÅŸÃ¼k - Sadece reklam gÃ¶ster
}

# Model gerÃ§ek alÄ±cÄ±larÄ±n %98'ini yakalÄ±yor
# Minimal false negative â†’ Maksimum gelir
```

### Model'i SÄ±fÄ±rdan EÄŸit

```bash
# 5-fold CV ile full training pipeline
python -m src.models.train_kfold

# Ã‡Ä±ktÄ±: models/lightgbm_v3.txt, models/xgboost_v3.json
```

### Phase OptimizasyonlarÄ±nÄ± Ã‡alÄ±ÅŸtÄ±r

```bash
# Phase 3: Hiperparametre optimizasyonu (Optuna)
python -m src.models.phase3_optuna_tuning

# Phase 4: Ensemble yÃ¶ntemleri
python -m src.models.phase4_ensemble
```

---

## ğŸ“ Proje YapÄ±sÄ±

```
â”œâ”€â”€ archive/                 (883 MB - Orijinal ham veri)
â”‚   â”œâ”€â”€ train.parquet        (11.5M event)
â”‚   â”œâ”€â”€ val.parquet
â”‚   â””â”€â”€ test.parquet
â”‚
â”œâ”€â”€ data/                    (602 MB - Ä°ÅŸlenmiÅŸ veri)
â”‚   â”œâ”€â”€ v3/                  (v3.0 baseline - 24 Ã¶zellik)
â”‚   â”‚   â”œâ”€â”€ train_sessions_v3.parquet  (2.2M session)
â”‚   â”‚   â”œâ”€â”€ val_sessions_v3.parquet
â”‚   â”‚   â””â”€â”€ test_sessions_v3.parquet
â”‚   â”œâ”€â”€ v3_final/            (Phase optimizasyonlarÄ± - 29 Ã¶zellik)
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ models/                  (23 MB - EÄŸitilmiÅŸ modeller)
â”‚   â”œâ”€â”€ lightgbm_v3.txt      (v3.0 production model â­)
â”‚   â”œâ”€â”€ xgboost_v3.json      (v3.0 alternatif)
â”‚   â”œâ”€â”€ best_*.pkl/txt       (Phase 3 optimize edilmiÅŸ modeller)
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ reports/                 (2.5 MB - Raporlar & gÃ¶rseller)
â”‚   â”œâ”€â”€ FINAL_PROJECT_REPORT.md       (KapsamlÄ± â­â­â­)
â”‚   â”œâ”€â”€ PROJECT_PRESENTATION.md       (Sunum â­â­â­)
â”‚   â”œâ”€â”€ final_report_v3.md           (v3.0 detaylarÄ±)
â”‚   â”œâ”€â”€ final_report_v6.md           (v6.0 analizi)
â”‚   â”œâ”€â”€ *.csv                         (7 sonuÃ§ dosyasÄ±)
â”‚   â”œâ”€â”€ final_visuals/               (10 profesyonel PNG â­)
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ final_reports/           (Veri seti dokÃ¼mantasyonu)
â”‚   â”œâ”€â”€ ORIGINAL_DATASET_REPORT.md    (Ham veri analizi â­)
â”‚   â””â”€â”€ PROCESSED_DATASET_REPORT.md   (Ä°ÅŸlenmiÅŸ veri â­)
â”‚
â”œâ”€â”€ src/                     (232 KB - Kaynak kod)
â”‚   â”œâ”€â”€ models/              (10 script - eÄŸitim & optimizasyon)
â”‚   â”œâ”€â”€ features/            (5 script - Ã¶zellik mÃ¼hendisliÄŸi)
â”‚   â”œâ”€â”€ data/                (3 script - veri Ã¶n iÅŸleme)
â”‚   â”œâ”€â”€ evaluation/          (3 script - metrikler & analiz)
â”‚   â”œâ”€â”€ analysis/            (1 script - Ã¶zellik analizi)
â”‚   â”œâ”€â”€ utils/               (2 script - config & utilities)
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ README.md                (Bu dosya - Proje Ã¶zeti)
â”œâ”€â”€ requirements.txt         (Python baÄŸÄ±mlÄ±lÄ±klarÄ±)
â””â”€â”€ .gitignore              (Git ignore kurallarÄ±)
```

**Toplam:** 2.2 GB (6.6 GB'den optimize edildi)

---

## ğŸ”¬ Metodoloji

### Veri Pipeline'Ä±

```
Ham Eventler: 11.5M
    â†“ Session BirleÅŸtirme
3.7M Session
    â†“ Kalite Filtreleme
2.2M Temiz Session
    â†“ Ã–zellik MÃ¼hendisliÄŸi
24 Ã–zellik
    â†“ Train/Val/Test BÃ¶lme
Final Veri Seti
    â†“ v3.0 LightGBM
Production Model
```

### Ã–zellik MÃ¼hendisliÄŸi

**24 Session-Seviye Ã–zellik:**

1. **EtkileÅŸim (2):** `n_events`, `n_unique_products`
2. **Zamansal (11):** Session sÃ¼resi, saat desenleri, hafta iÃ§i desenleri
3. **Fiyat (5):** Ortalama, std, min, max, toplam
4. **Kategori (4):** 4 seviyede tekil kategoriler
5. **MÃ¼hendislenmiÅŸ (4):** `event_rate`, `product_diversity`, `engagement_intensity`, `price_velocity`

**En Ã–nemli 3:**
1. `n_events` - %18.3 Ã¶nem
2. `session_duration_seconds` - %14.5 Ã¶nem
3. `event_rate` (mÃ¼hendislenmiÅŸ) - %12.1 Ã¶nem â­

### DeÄŸerlendirme Stratejisi

- **Ana Metrik:** AUC (sÄ±ralama yeteneÄŸi)
- **Ä°kincil:** F1, Precision, Recall
- **Overfitting KontrolÃ¼:** Train-Test gap analizi
- **Validation:** Sadece hiperparametre tuning iÃ§in
- **Test:** Final deÄŸerlendirme (optimizasyon sÄ±rasÄ±nda hiÃ§ dokunulmadÄ±)

### Hesaplama KaynaklarÄ±

- **Lokal:** MacBook (M-serisi chip)
- **Cloud:** Google Colab (paralel Optuna denemeleri)
- **Toplam SÃ¼re:** ~20 saat deney

---

## ğŸ“ˆ Performans Kriterleri

### Confusion Matrix (Test Seti)

```
                 Tahmin HayÄ±r   Tahmin Evet
GerÃ§ek HayÄ±r        384,219       73,806
GerÃ§ek Evet           1,654       81,362
```

**Metrikler:**
- Accuracy: %85.9
- Recall: %98.0 (Sadece 1,654 / 83,016 kaÃ§Ä±rÄ±ldÄ±!)
- Precision: %52.4
- Specificity: %83.9

### Ä°ÅŸ Metrikleri

**Kampanya VerimliliÄŸi:**
- En Ã¼st %30'u hedefle â†’ %95+ alÄ±cÄ± yakalama
- BÃ¼tÃ§e tahsisi optimize edildi
- Minimal false negative

**ROI Etkisi:**
- v3.0 recall 0.98 vs ExtraTrees 0.77
- %21 daha fazla mÃ¼ÅŸteri yakalandÄ± = Ã¶nemli gelir artÄ±ÅŸÄ±

---

## ğŸ“ Ã–ÄŸrenilen Dersler & En Ä°yi Pratikler

### Ä°ÅŸe Yarayanlar

âœ… **Veri Kalitesi OdaÄŸÄ±**
- Session birleÅŸtirme (mÃ¼kerrer/kÄ±smi sessionlarÄ± temizleme)
- Kalite filtreleme (bot tespiti, outlier temizleme)
- 11.5M â†’ 2.2M (%81 azalma, bÃ¼yÃ¼k kalite kazancÄ±)

âœ… **Ã–nce Basit Baseline**
- v3.0: VarsayÄ±lan LightGBM + temiz veri
- GÃ¼Ã§lÃ¼ temel oluÅŸturuldu
- Sofistike yÃ¶ntemlerle bile geÃ§ilmesi zor

âœ… **Sistematik Deney**
- 10 farklÄ± yaklaÅŸÄ±m dokÃ¼mante edildi
- Her baÅŸarÄ±sÄ±zlÄ±k deÄŸerli dersler Ã¶ÄŸretti
- Net karÅŸÄ±laÅŸtÄ±rma Ã§erÃ§evesi

âœ… **Ä°ÅŸ-Metrik Hizalama**
- Recall iÅŸ deÄŸeri iÃ§in Ã¶nceliklendi
- Sadece AUC skorlarÄ± kovalamadÄ±k
- 98/100 mÃ¼ÅŸteri yakalama = gerÃ§ek etki

### Ä°ÅŸe Yaramayanlar

âŒ **Ã–zellik NiceliÄŸi Kaliteden Ã–nce**
- v5.0: 68 Ã¶zellik overfitting yarattÄ±
- **Ã–ÄŸrenilen:** SeÃ§ilmiÅŸ 24 Ã¶zellik > 68 rastgele Ã¶zellik

âŒ **Validation-OdaklÄ± Optimizasyon**
- Grid search validation set'e overfit oldu
- **Ã–ÄŸrenilen:** AyrÄ± holdout set kritik

âŒ **KÃ¶r Hiperparametre Tuning**
- 50 Optuna denemesi v3.0'Ä± kÃ¶tÃ¼leÅŸtirdi
- **Ã–ÄŸrenilen:** VarsayÄ±lan parametreler genelde iyi kalibre edilmiÅŸ

âŒ **Ensemble iÃ§in Ensemble**
- 10 ensemble yÃ¶ntemi, hepsi baÅŸarÄ±sÄ±z
- **Ã–ÄŸrenilen:** Modeller tamamlamalÄ±, sadece birleÅŸmemeli

---

## ğŸ”® Gelecek Ä°yileÅŸtirmeler

Ek kaynaklar bulunursa:

### 1. Daha Fazla Veri (En YÃ¼ksek Etki!)
- **Mevcut:** 2.2M session
- **Hedef:** 10M+ session
- **Beklenen KazanÃ§:** +%2-3 AUC
- **Neden:** Daha saÄŸlam desen Ã¶ÄŸrenme

### 2. Harici Ã–zellikler
- ÃœrÃ¼n kategori hiyerarÅŸileri
- Fiyat trend verileri
- Mevsimsellik gÃ¶stergeleri
- KullanÄ±cÄ± demografisi
- **Beklenen KazanÃ§:** +%1-2 AUC

### 3. Derin Ã–ÄŸrenme (Uzun vadeli)
- Sequence modelleri (LSTM/Transformer)
- Graph Neural Networks (Ã¼rÃ¼n iliÅŸkileri)
- **Gereksinim:** Minimum 10M+ Ã¶rnek

### 4. A/B Test Framework
- GerÃ§ek dÃ¼nya deployment'Ä±
- Ä°ÅŸ metriklerini takip (ROI, conversion)
- Model gÃ¼ncellemeleri iÃ§in feedback loop

---

## ğŸ“„ Lisans

MIT License - Detaylar iÃ§in LICENSE dosyasÄ±na bakÄ±n.

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r. Veri seti sentetik/anonimleÅŸtirilmiÅŸtir.

---

## ğŸ“ Ä°letiÅŸim & AlÄ±ntÄ±lama

### Yazar
**Recep Ã–ztÃ¼rk**
- GitHub: [@recepztrk](https://github.com/recepztrk)
- Proje: [ecommerce-purchase-prediction](https://github.com/recepztrk/ecommerce-purchase-prediction)

### AlÄ±ntÄ±lama

Bu projeyi kullanÄ±rsanÄ±z veya faydalÄ± bulursanÄ±z:

```bibtex
@misc{ozturk2025ecommerce,
  author = {Ã–ztÃ¼rk, Recep},
  title = {E-Commerce SatÄ±n Alma Tahmini: Optimizasyon YaklaÅŸÄ±mlarÄ±nÄ±n Sistematik Ä°ncelemesi},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/recepztrk/ecommerce-purchase-prediction}
}
```

---

## ğŸ† Proje Ä°statistikleri

- **Kod SatÄ±rÄ±:** ~5,100 (Python)
- **DokÃ¼mantasyon:** ~5,000 satÄ±r (Markdown)
- **Denemeler:** 10 optimizasyon yaklaÅŸÄ±mÄ±
- **EÄŸitilen Modeller:** 30+
- **GÃ¶rseller:** 10 profesyonel grafik
- **Proje SÃ¼resi:** [SÃ¼reniz]
- **Final Durum:** âœ… TamamlandÄ±

---

## ğŸ“ DeÄŸiÅŸiklik GÃ¼nlÃ¼ÄŸÃ¼

### v3.0 (Final) - AralÄ±k 2025
- âœ… Production model seÃ§ildi (v3.0 LightGBM Baseline)
- âœ… 10 optimizasyon yaklaÅŸÄ±mÄ± test edildi ve dokÃ¼mante edildi
- âœ… KapsamlÄ± dokÃ¼mantasyon oluÅŸturuldu
- âœ… 10 profesyonel gÃ¶rsel Ã¼retildi
- âœ… Kod temizliÄŸi ve organizasyon (4.4GB'dan 2.2GB'ye dÃ¼ÅŸÃ¼rÃ¼ldÃ¼)
- âœ… TÃ¼m denemeler tekrar Ã¼retilebilir

### v2.0
- GeliÅŸmiÅŸ Ã¶zellikler ve hiperparametre tuning eklendi
- Test AUC: 0.6107 (+%2.88 v1.0'a gÃ¶re)

### v1.0
- Ä°lk baseline implementasyonu
- Test AUC: 0.5936

---

**Dipnot: Bazen basit Ã§Ã¶zÃ¼m en iyi Ã§Ã¶zÃ¼mdÃ¼r.** ğŸš€
